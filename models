import pandas as pd
import pickle
import numpy as np
from google.colab import drive
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer
from collections import Counter

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Load the data from the pickled file
file_path = '/content/drive/My Drive/synthetic_dataset/goal_set.p'
with open(file_path, 'rb') as file:
    consultation_data = pickle.load(file)

test_data = consultation_data['train']

# Extract explicit and implicit symptoms along with their disease tags
disease_tags = []
explicit_symptoms_list = []
implicit_symptoms_list = []

for item in test_data:
    disease_tags.append(item['disease_tag'])
    explicit_symptoms = list(item['goal']['explicit_inform_slots'].keys())
    implicit_symptoms = list(item['goal']['implicit_inform_slots'].keys())
    explicit_symptoms_list.append(", ".join(explicit_symptoms))
    implicit_symptoms_list.append(", ".join(implicit_symptoms))

# Create DataFrame
df = pd.DataFrame({
    'Disease Tag': disease_tags,
    'Explicit Symptoms': explicit_symptoms_list,
    'Implicit Symptoms': implicit_symptoms_list
})

# Display the DataFrame
print(df.head(10))

# Define NDCG calculation functions
def dcg_score(y_true, y_score, k=10):
    order = np.argsort(y_score)[::-1]
    y_true = np.take(y_true, order[:k])
    gain = 2 ** y_true - 1
    discounts = np.log2(np.arange(len(y_true)) + 2)
    return np.sum(gain / discounts)

def ndcg_score(y_true, y_score, k=10):
    best = dcg_score(y_true, y_true, k)
    actual = dcg_score(y_true, y_score, k)
    return actual / best

# Prepare the data
X = df['Explicit Symptoms'] + " " + df['Implicit Symptoms']
y = df['Disease Tag']

# Encode the labels
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize text data with TF-IDF
vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=5000, sublinear_tf=True)
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

# Define models and their parameter grids
models = {
    'Random Forest': (RandomForestClassifier(random_state=42), {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }),
    'Gradient Boosting': (GradientBoostingClassifier(random_state=42), {
        'n_estimators': [100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }),
    'Logistic Regression': (LogisticRegression(max_iter=10000, random_state=42), {
        'C': [0.1, 1, 10],
        'penalty': ['l2']
    }),
    'SVM': (SVC(probability=True, random_state=42), {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf']
    })
}

results = {}

for model_name, (model, param_grid) in models.items():
    print(f"Training {model_name}...")
    
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_train, y_train)
    best_model = grid_search.best_estimator_
    
    # Predict and calculate accuracy
    y_pred = best_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"{model_name} Accuracy: {accuracy:.2f}")
    
    # Calculate NDCG for the model
    y_test_bin = MultiLabelBinarizer().fit_transform([[label] for label in y_test])
    y_score = best_model.predict_proba(X_test)
    
    ndcg_scores = [ndcg_score(y_test_bin[i], y_score[i], k=10) for i in range(len(y_test))]
    mean_ndcg_10 = np.mean(ndcg_scores)
    print(f"{model_name} NDCG@10: {mean_ndcg_10:.5f}")
    
    ndcg_scores_5 = [ndcg_score(y_test_bin[i], y_score[i], k=5) for i in range(len(y_test))]
    mean_ndcg_5 = np.mean(ndcg_scores_5)
    print(f"{model_name} NDCG@5: {mean_ndcg_5:.5f}")
    
    results[model_name] = {
        'model': best_model,
        'accuracy': accuracy,
        'ndcg_10': mean_ndcg_10,
        'ndcg_5': mean_ndcg_5
    }

# Choose the best model based on accuracy (you can also choose based on NDCG scores)
best_model_name = max(results, key=lambda name: results[name]['accuracy'])
best_model = results[best_model_name]['model']
print(f"Best Model: {best_model_name} with Accuracy: {results[best_model_name]['accuracy']:.2f}")

# Initialize an empty dictionary to store the results
callme = {}

# Initialize an empty set to store the unique user input symptoms
user_input_symptoms = set()

# Symptom matching and disease prediction logic
explicit_input = input("Enter explicit symptoms (comma-separated): ").strip().lower()
input_explicit_symptoms = [symptom.strip() for symptom in explicit_input.split(',')]
matching_symptoms = {}

# Find all implicit symptoms associated with the input explicit symptoms
for item in test_data:
    explicit_info = item.get('goal', {}).get('explicit_inform_slots', {})
    implicit_info = item.get('goal', {}).get('implicit_inform_slots', {})
    disease_tag = item['disease_tag']
    if any(symptom.lower() in [key.lower() for key in explicit_info] for symptom in input_explicit_symptoms):
        matching_symptoms[disease_tag] = matching_symptoms.get(disease_tag, set())
        matching_symptoms[disease_tag].update(implicit_info.keys())

# Store matching implicit symptoms along with user's explicit symptoms for each disease in the 'callme' memory
if matching_symptoms:
    for disease_tag, implicit_symptoms in matching_symptoms.items():
        for symptom in implicit_symptoms:
            callme[(disease_tag, symptom)] = input_explicit_symptoms
            # Add the user's input symptoms to the set
            user_input_symptoms.update(input_explicit_symptoms)

# Create a dictionary to store the user input symptoms only if it's not already added
combined_symptoms = {}
if user_input_symptoms:
    combined_symptoms['User Input Symptoms'] = list(user_input_symptoms)

# Print the results
if callme:
    for (disease_tag, symptom), explicit_symptoms in callme.items():
        print(f"Disease: {disease_tag}, Implicit Symptom: {symptom}, Explicit Symptoms: {', '.join(explicit_symptoms)}")
else:
    print("No matching implicit symptoms found.")

# Print the user input symptoms
if user_input_symptoms:
    print("User Input Symptoms:", ', '.join(combined_symptoms['User Input Symptoms']))
else:
    print("No user input symptoms provided.")

def find_direct_matches(callme):
    direct_matches = []

    for (disease, implicit_symptom), explicit_symptoms in callme.items():
        for explicit_symptom in explicit_symptoms:
            if implicit_symptom.lower() == explicit_symptom.lower():
                direct_matches.append((disease, implicit_symptom, explicit_symptom))

    return direct_matches

# Finding the direct matches
direct_matches = find_direct_matches(callme)

# Saving the direct matches in disease_list dictionary
disease_list = {}
for disease, implicit_symptom, explicit_symptom in direct_matches:
    if disease not in disease_list:
        disease_list[disease] = []
    disease_list[disease].append((implicit_symptom, explicit_symptom))

# Printing the disease_list dictionary
print("disease_list dictionary:")
for disease, symptoms in disease_list.items():
    print(f"Disease: {disease}")

# If no direct matches found, print a message
if not disease_list:
    print("No direct matches found.")

# Initialize an empty dictionary to store results
result = {}

# Function to find and print implicit symptoms for a given disease
def find_and_print_implicit_symptoms(callme, disease_name, result):
    found = False
    for (disease, implicit_symptom), explicit_symptoms in callme.items():
        if disease.lower() == disease_name.lower():
            found = True
            result[(disease, implicit_symptom)] = explicit_symptoms
            print(f"Disease: {disease}, Implicit Symptom: {implicit_symptom}, Explicit Symptoms: {', '.join(explicit_symptoms)}")
    if not found:
        print(f"No implicit symptoms found for {disease_name}.")

# Printing the disease_list dictionary
print("disease_list dictionary:")
for disease_name in disease_list.keys():
    print(f"Disease: {disease_name}")
    # Call function to find and print implicit symptoms, without modifying callme during iteration
    find_and_print_implicit_symptoms(callme, disease_name, result)

# Print the result dictionary
print("\nResult dictionary:")
for key, value in result.items():
    print(f"{key}: {value}")

import pandas as pd
import pickle
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Load the data from the pickle file
file_path = '/content/drive/My Drive/synthetic_dataset/disease_symptom.p'
with open(file_path, 'rb') as file:
    disease_data = pickle.load(file)

# Convert the data into a DataFrame
data = {
    'disease': [],
    'symptom': [],
    'score': []
}

for disease, info in disease_data.items():
    for symptom, score in info['symptom'].items():
        data['disease'].append(disease)
        data['symptom'].append(symptom)
        data['score'].append(score)

df = pd.DataFrame(data)



# Function to find and print scores based on input
def find_scores(disease_name, implicit_symptom):
    # Find scores based on input
    score_df = df[(df['disease'] == disease_name) & (df['symptom'] == implicit_symptom)]

    # Sort scores from highest to lowest
    sorted_score_df = score_df.sort_values(by='score', ascending=False)

    # Prepare list to store results
    results = []

    # Append results to the list
    if not sorted_score_df.empty:
        for idx, row in sorted_score_df.iterrows():
            results.append((row['symptom'], row['score']))
    else:
        results.append((implicit_symptom, 'No scores found'))

    return results

# Function to find and print matching implicit symptoms based on explicit symptoms
def find_matching_implicit_symptoms(explicit_symptoms):
    # Matching implicit symptoms
    matching_symptoms = set()

    # Check for partial matching implicit symptoms
    for item in df.itertuples():
        for explicit_symptom in explicit_symptoms:
            explicit_words = explicit_symptom.lower().split()
            implicit_words = item.symptom.lower().split()
            # Check if all explicit words are present in implicit symptom
            if all(word in implicit_words for word in explicit_words) and \
               all(word in explicit_words for word in implicit_words):
                matching_symptoms.add(item.symptom)

    return matching_symptoms



# Process each input from the result memory and store results
all_results = []
for (disease_name, implicit_symptom), explicit_symptoms in result.items():
    all_results.extend(find_scores(disease_name, implicit_symptom))

# Use a dictionary to keep track of the highest score for each symptom
symptom_scores = {}
for symptom, score in all_results:
    if symptom not in symptom_scores or score > symptom_scores[symptom]:
        symptom_scores[symptom] = score

# Sort the symptoms by their highest score in descending order
sorted_symptoms = sorted(symptom_scores.items(), key=lambda x: x[1], reverse=True)

# Print only the first 10 results with order number
for idx, (symptom, score) in enumerate(sorted_symptoms[:10], start=1):
    print(f"{idx}. {symptom}, {score}")

# Initialize a set to store the matched implicit symptoms
matching_implicit_symptoms = set()

# Take user input for implicit symptoms
implicit_input = input("Enter implicit symptoms you have (comma-separated): ")

# Split the input into individual implicit symptoms
implicit_symptoms = [symptom.strip() for symptom in implicit_input.split(',')]

# Find matching implicit symptoms based on user input
matching_implicit_symptoms = find_matching_implicit_symptoms(implicit_symptoms)

# Check if any matching implicit symptoms are found
if matching_implicit_symptoms:
    print("\nMatched Implicit Symptoms:")
    for symptom in matching_implicit_symptoms:
        print(f"- {symptom}")

    # Add matched implicit symptoms to combined_symptoms without modifying existing data
    if 'Matched Implicit Symptoms' in combined_symptoms:
        combined_symptoms['Matched Implicit Symptoms'].update(matching_implicit_symptoms)
    else:
        combined_symptoms['Matched Implicit Symptoms'] = matching_implicit_symptoms
else:
    print("No matching implicit symptoms found.")

import pandas as pd
import pickle
from google.colab import drive
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from collections import Counter

# Mount Google Drive
drive.mount('/content/drive', force_remount=True)

# Load the data from the pickled file
file_path = '/content/drive/My Drive/synthetic_dataset/goal_set.p'
with open(file_path, 'rb') as file:
    consultation_data = pickle.load(file)

# Extract explicit and implicit symptoms along with their disease tags
disease_tags = []
explicit_symptoms_list = []
implicit_symptoms_list = []

for item in consultation_data['train']:
    disease_tags.append(item['disease_tag'])
    explicit_symptoms = list(item['goal']['explicit_inform_slots'].keys())
    implicit_symptoms = list(item['goal']['implicit_inform_slots'].keys())
    explicit_symptoms_list.append(", ".join(explicit_symptoms))
    implicit_symptoms_list.append(", ".join(implicit_symptoms))

# Create DataFrame
df = pd.DataFrame({
    'Disease Tag': disease_tags,
    'Explicit Symptoms': explicit_symptoms_list,
    'Implicit Symptoms': implicit_symptoms_list
})

# Define and train the Random Forest model
X_explicit = df['Explicit Symptoms']
y = df['Disease Tag']

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Vectorize explicit text data
vectorizer = CountVectorizer()
X_explicit_vectorized = vectorizer.fit_transform(X_explicit)

# Train Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_explicit_vectorized, y)

# Function to predict diseases based on explicit symptoms
def predict_diseases(explicit_symptoms, top_n=5):
    symptoms_vectorized = vectorizer.transform([explicit_symptoms])
    probas = model.predict_proba(symptoms_vectorized)
    top_indices = probas.argsort(axis=1)[:, -top_n:][:, ::-1]
    predicted_diseases = label_encoder.inverse_transform(top_indices.flatten())
    return predicted_diseases.reshape(-1, top_n)

# Ensure the keys exist and have values
if 'User Input Symptoms' in combined_symptoms and 'Matched Implicit Symptoms' in combined_symptoms:
    # Combine user input and matched implicit symptoms into a single set
    all_symptoms_set = set(combined_symptoms['User Input Symptoms']).union(combined_symptoms['Matched Implicit Symptoms'])

    # Join all symptoms into a single string
    combined_symptoms_str = ", ".join(all_symptoms_set)

    # Predict top 5 diseases based on combined symptoms
    top_5_diseases = predict_diseases(combined_symptoms_str)
    # Count occurrences of each disease prediction
    disease_counts = Counter(top_5_diseases.flatten())

    # Sort diseases by count in descending order
    sorted_diseases = sorted(disease_counts.items(), key=lambda x: x[1], reverse=True)

    # Print the top 5 predicted diseases
    print("Top 5 Predicted Diseases:")
    for idx, (disease, count) in enumerate(sorted_diseases[:5], start=1):
        print(f"{idx}. {disease} ")
else:
    print("Combined symptoms dictionary does not contain required keys.")
